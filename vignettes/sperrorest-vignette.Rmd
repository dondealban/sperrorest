---
title: "sperrorest-vignette: Spatial modeling using statistical learning techniques"
author: "Alexander Brenning, Patrick Schratz"
date: "`r Sys.Date()`"
output: 
    rmarkdown::html_vignette:
      toc: true
vignette: >
  %\VignetteIndexEntry{sperrorest-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, echo=FALSE, cache=FALSE}
library(knitr)
opts_chunk$set(cache = TRUE,
               fig.align = "center",
               collapse = TRUE,
               fig.width = 7,
               fig.height = 5)
opts_knit$set(width = 125)
```

# Data and packages

```{r, message=FALSE}
library(rpart)
library(MASS)
library(ipred)
library(sperrorest)
```

The `maipo` data set from Marco Pena is used. 
```{r}
data("maipo", package = "sperrorest")

data("ecuador", package = "sperrorest")
```

Variable description:

**Response**  
  - `croptype`: response variable (factor) with 4 levels  
  
**Predictors**  
  - `b`[12-87]: spectral data, e.g. b82 = image date #8, spectral band #2  
  - `ndvi`[01-08]: Normalized Differenced Vegetation Index, e.g. #8 = image date #8  
  - `ndwi`[01-08]: Normalized Differenced Water Index, e.g. #8 = image date #8  
  
**Others**  
  - `field`: field identifier (grouping variable - not to be used as predictor)  
  - `utmx`, `utm`y: x/y location; not to be used as predictors  

# Preprocessing

Transform some of the predictor variables:

```{r}
predictors <- colnames(maipo)[5:ncol(maipo)]
# Construct a formula:
fo <- as.formula(paste("croptype ~", paste(predictors, collapse = "+")))
```

Take a quick look at (some) correlations among the predictors:
```{r}
co <- abs(cor(maipo[, predictors]) * 100)
co[co < 70] <- 0 # mask out weak/moderate correlations
head(round(co))
```


# Modeling

## Linear discriminant analysis (LDA)

Fit a model with all predictors:
```{r}
fit <- MASS::lda(fo, data = maipo)
```

Predict the croptype with the fitted model and calculate the average misclassification error rate (MER):
```{r}
pred <- predict(fit, newdata = maipo)$class
mean(pred != maipo$croptype)
```

Take a look at the confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```


## Classification Tree

Fit a model with all predictors:

```{r}
fit <- rpart(fo, data = maipo)
#            control = rpart.control(cp=0.01))

## optional: view the classiciation tree
# par(xpd = TRUE)
# plot(fit)
# text(fit, use.n = TRUE)
```

Again, predict the croptype with the fitted model and calculate the average MER:
```{r}
pred <- predict(fit, newdata = maipo, type = "class")
mean(pred != maipo$croptype)
```

And take a look at the confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```

Note that some classes may be over-/underpredicted, i.e. remotely-sensed crop areas can be biased even if accuracy is high!:

```{r}
summary(pred)
summary(maipo$croptype)
```

## bagging (ipred)

The same can be done using the `bagging()` function from the `ipred` package. This is a previous version of the famous `randomForest()` by Leo Breiman. For some reason `randomForest()` does introduce problems when being paralized. Hence `bagging()` is used in this vignette. However, `randomForest()` works fine with the sequential `sperrorest()` function and should be prefered over `bagging()`. 

```{r}
fit <- bagging(fo, data = maipo, coob = TRUE)
fit
```
Training-set misclassification error rate (MER) 
```{r}
pred <- predict(fit, newdata = maipo, type = "class")
mean(pred != maipo$croptype)
```

Confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```

- Almost no missclassification! (only one observation)
- Even the OOB (out-of-bag) estimate of the error rate is < 1%.
- Too good to be true? We'll see...

## Random Forest

(This will take some time...)
```{r}
fit <- randomForest(fo, data = maipo, importance = TRUE)
fit
```

Variable importance plot:
```{r}
varImpPlot(fit, type = 1, pch = 19, col = "blue", 
           main = "Permutation-based variable importance")
```

Variable importance plots for specific crop types
```{r}
partialPlot(fit, maipo, x.var = "ndvi01", which.class = "crop1")
partialPlot(fit, maipo, x.var = "ndvi01", which.class = "crop3")
```

Training-set misclassification error rate (MER) 
```{r}
pred <- predict(fit, newdata = maipo, type = "class")
mean(pred != maipo$croptype)
```

Confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```

- No misclassification at all!
- Even RF's OOB (out-of-bag) estimate of the error rate is <1%.
- Too good to be true? We'll see...


# Cross-validation estimation of predictive performance

# LDA

We need to set up some functions to create a wrapper predict function of the LDA model for `sperrorest`. 

```{r}
library(nnet)
majority <- function(x) {
  levels(x)[which.is.max(table(x))]
}
```

```{r}
majority.filter <- function(x, fac) {
  for (lev in levels(fac)) {
    x[ fac == lev ] <- majority(x[ fac == lev ])
  }
  x
}
```

```{r}
lda.predfun <- function(object, newdata, fac = NULL) {
  pred <- predict(object, newdata = newdata)$class
  if (!is.null(fac)) pred <- majority.filter(pred, newdata[,fac]) 
  return(pred)
}
```

Finally, we can run `sperrorest` with a non-spatial sampling setup (`partition.cv`):

```{r}
res.lda.nsp <- res <- sperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                                 model.fun = lda,
                                 pred.fun = lda.predfun, 
                                 pred.args = list(fac = "field"),
                                 smp.fun = partition.cv, 
                                 smp.args = list(repetition = 1:4, nfold = 5),
                                 err.rep = TRUE, err.fold = FALSE)
round(summary(res.lda.nsp$error.rep), 3)
```

To run a spatial cross-validation at the field level, we can use `partition.factor.cv` as the sampling function. Subsequently, we have to specify the location of the fields. We can do so using the `field` variable of our data set and put in `smp.args`: 

```{r}
res.lda.sp <- sperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                         model.fun = lda,
                         pred.fun = lda.predfun, 
                         pred.args = list(fac = "field"),
                         smp.fun = partition.factor.cv, benchmark = T,
                         smp.args = list(fac = "field", repetition = 1:4, nfold = 5),
                         err.rep = TRUE, err.fold = FALSE)
res.lda.sp$benchmark
```

parsperrorest test with LDA (non-spatial)
```{r}
res.lda.sp.par <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                               model.fun = lda,
                               pred.fun = lda.predfun, 
                               #pred.args = list(fac = "field"),
                               smp.fun = partition.cv,
                               smp.args = list(repetition = 1:4, nfold = 5),
                               par.args = list(par.mode = 3, par.units = 2, 
                                               lb = F, high = F),
                               err.rep = TRUE, err.fold = T,
                               benchmark = TRUE, verbose = "all")
```

# Bagging

This time we do not need to set up a custom pred.fun as the generic `predict()` works fine. 
Running `sperrorest()` takes some time here (a few minutes depending on your CPU power). 


```{r}
res.bagg.sp <- sperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                          model.fun = bagging,
                          pred.args = list(fac = "field"),
                          smp.fun = partition.factor.cv,
                          smp.args = list(fac = "field",
                                          repetition = 1:4, nfold = 5),
                          err.rep = TRUE, err.fold = TRUE,
                          benchmark = TRUE, verbose = "all")
```

To speed things up, we can use `parsperrorest()` and see the time difference. Note that we have three parallel modes to choose from!  
In this example all three modes are presented and their differences are explained.  
In this vignette we will always use 2 cores to ensure that this example is working for everybody.  
You can of course increase the number of cores and also the number of repetitions/folds to your desire! 
Note that we will not use any console in this vignette to keep it tidy.
However you can just change this setting to your desire using the `verbose` argument. 

`par.mode = 1` uses a `mclapply` setup and will not work on Windows systems unless only 1 core is used (which results in no parallelization)! 
Due to this contraint this mode is not used in this vignette. 
So if you are reading this and running a Windows machine, jump to `par.mode = 2` or `par.mode = 3` example!
The advantage of using `par.mode = 1` compared to `par.mode = 2` is that (in theory) console output is given here.
However this is currently not working and the reason is still unknown.
So whether you rely on progress tracking or not, `par.mode = 1` is not efficently working right now and `par.mode = 2` or `par.mode = 3` should be used! 

`par.mode = 2` also uses `mclapply` in the background but works for all operating systems. 
However the drawback is that no console output can be printed to the console. 
On the other hand, this mode is the fastest one among all three.

```{r}
res.bagg.sp.par2 <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                                   model.fun = bagging,
                                   pred.args = list(fac = "field"),
                                   smp.fun = partition.factor.cv,
                                   smp.args = list(fac = "field", 
                                                   repetition = 1:10, nfold = 5),
                                   par.args = list(par.mode = 2, par.units = 2, 
                                                   lb = FALSE, high = FALSE),
                                   err.rep = TRUE, err.fold = TRUE,
                                   benchmark = TRUE, verbose = FALSE)
res.bagg.sp.par2$benchmarks$runtime.performance
```

`par.mode = 3` is different from `par.mode = 1` and `par.mode = 2` as it uses `foreach()` to perform the parallelization. 
While this ensures progress tracking and works on all platforms, it less efficient than `mclapply` approaches which are used within `par.mode = 1` and `par.mode = 2`. 
Also `par.args` `lb` and `high` are not needed in this mode. 

```{r}
res.bagg.sp.par3 <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                                   model.fun = bagging,
                                   pred.args = list(fac = "field"),
                                   smp.fun = partition.factor.cv,
                                   smp.args = list(fac = "field", 
                                                   repetition = 1:10, nfold = 5),
                                   par.args = list(par.mode = 3, par.units = 2),
                                   err.rep = TRUE, err.fold = TRUE,
                                   benchmark = TRUE, verbose = FALSE)
res.bagg.sp.par3$benchmarks$runtime.performance
```
