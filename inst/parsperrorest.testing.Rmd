---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
date: "11.12.2016"
---

```{r, echo=FALSE, cache=FALSE}
library(knitr)
opts_chunk$set(cache = TRUE,
               eval = T)
```

# Überblick

Zusammenfassung aller `sperrorest()` Parallelisierungs-Versuche welche ich in den letzten Monaten durchgeführt wurden. 

Das Hauptproblem ist, dass zwar alle in ihren jeweiligen Beispielen laufen (`rpart`), jedoch immer wieder (andere!) Probleme bei anderen Varianten wie `MASS::lda()` und `ipred::bagging()` auftreten. Letzere Versuche sind im File `sperrorest-vignette.Rmd` einzusehen. Mal fehlt der `error.rep`, mal wird eine Liste zu viel geschrieben und es gibt einen Zuweisungsfehler in `mclapply`, mal wird eine custom function nicht ins environment aller worker exporiert...  
Das Problem ist, dass die Fehler nicht konsistent sind für jede Funktion sondern sich ändern basierend auf den genutzten Paketen (`MASS::lda()` oder `ipred::bagging()`). Das macht die ganze Geschichte quasi unmöglich zum generellen debuggen, da der Fix für ein Package die Funktion für das andere wieder bricht. 

Mein Favorit ist der Ansatz mit dem `pbapply` package. Das ist quasi ein erweiterter Ansatz des Codes von Tobias Herrmann (TH). Hier werden die langsameren Ansätze von TH gestrichen (`parallel::clusterApply` (`high = FALSE`) und prescheduling der workers bei `parallel::parApply` (`lb = TRUE`) und dazu gibt es noch eine progress bar. Siehe die Beispiele unten für Details. Die langsameren Ansätze sind auch nicht robuster als die fixeren, von daher bringen diese Einstellung nur weitere Konfusion für den Nutzer mit sich. 
Bei `pbapply::pbLapply()` wird für Windows Systeme ein Cluster erstellt und bei Unix Systemen mit `par.units` direkt die Anzahl der Kerne für `parallel::mclapply()` angegeben. 

* `parsperrorest.old()` ist die Funktion, welche die originale Funktion von TH enthält (`par.mode = 1 | 2`) sowie meine foreach Funktion (`par.mode = 3`). 

* `parsperrorest()` basiert auf dem `pbapply` package Ansatz wie oben beschrieben. 

# Vignette

Die Vignette sollte erstmal nur mit der sequentiellen `sperrorest()` geschrieben werden, da alle Parallelfunktionen mit den dort benutzten Funktionen Probleme bekommen.  
Ich schlage eine eigene Parallelvignette vor (sofern dies überhaupt nötig ist). Die basics werden ja auch in den Beispielen gezeigt. 

# Weitere Vorgehensweise (Vorschlag)

* Zwar gibt es viele Probleme mit den Parallelfunktionen, jedoch sollte man diese ins Paket einbinden mit einer warnung, dass das Verhalten abhängig ist von der jeweilig benutzten Funktion und man immer seine Resultate auf Vollständigkeit testen soll. Sollten zu viele Probleme auftreten, so soll man die sequentielle Version verwenden.  

* Ich würde zwei Modi Vorschlagen: Der erste ist der `pbapply` Ansatz, welcher automatisch zwischen `mclapply` und `parApply` unterscheidet nach Plattform Typ. Der Zweite ist der `foreach` Ansatz, der zwar langsamer läuft, aber manchmal stabiler.
Der `foreach` mode müsste dann noch aus `parsperrorest.old()` nach `parsperrorest()` exporiert werden. 

* Wir bekommen Nutzerfeedback mit bestimmten Funktionen aus dem wir lernen können.

# Beispiele

## Install sperorrest `dev` branch from Github
```{r, eval = T}
devtools::install_github("pat-s/sperrorest", ref = "dev")
library(sperrorest)
```


## parsperrorest.old 
* par.mode 1 & par.mode 2 von Tobias Herrmann
     * Nachteile: 
          * Nur auf Unix Systemen (mclapply)
          * Windows + Unix aber kein Konsolenoutput bzw. nur die Folds im `for` loop
          * manchmal "missing" functions (wenn eigens definiert)
     * Vorteile:
          * Schnell
       
* par.mode 3 von Patrick Schratz
    * Nachteile:
        * Langsamer als `apply` Versuche von par.mode 1 & 2
        * Probleme bei der Rückgabe von mehreren Objekten -> nicht immer konsistenst!
    * Vorteile: 
        * Konsolenoutput von jeder Rep & fold
        * Keine Probleme mit "missing" custom functions im environment
    

### parsperrorest.old mit par.mode = 2 (`parallel::parApply`)
* `high = TRUE` -> `parallel::parApply`
* par.mode == 2

```{r}
data(ecuador, package = "sperrorest") # Muenchow et al. (2012), see ?ecuador
fo <- slides ~ dem + slope + hcurv + vcurv + log.carea + cslope

# Example of a classification tree fitted to this data:
library(rpart)
mypred.rpart <- function(object, newdata) predict(object, newdata)[, 2]
ctrl <- rpart.control(cp = 0.005) # show the effects of overfitting
fit <- rpart(fo, data = ecuador, control = ctrl)

# Non-spatial 5-repeated 10-fold cross-validation:
mypred.rpart <- function(object, newdata) predict(object, newdata)[,2]
parapply.out <- parsperrorest.old(data = ecuador, formula = fo,
                                  model.fun = rpart, model.args = list(control = ctrl),
                                  pred.fun = mypred.rpart,
                                  verbose = FALSE,
                                  smp.fun = partition.cv, 
                                  smp.args = list(repetition = 1:20, nfold = 4), 
                                  par.args = list(par.mode = 2, par.units = 2, 
                                                  lb = FALSE, high = T),
                                  error.rep = TRUE, error.fold = TRUE)
```

### parsperrorest.old mit par.mode = 2 (`parallel::clusterApply()`)

* `high = FALSE` -> `parallel::clusterApply()`
* par.mode == 2
```{r}
clusterapply.out <- parsperrorest.old(data = ecuador, formula = fo,
                                      model.fun = rpart, model.args = list(control = ctrl),
                                      pred.fun = mypred.rpart,
                                      smp.fun = partition.cv, 
                                      smp.args = list(repetition = 1:20, nfold = 5), 
                                      par.args = list(par.mode = 1, par.units = 2, 
                                                      lb = FALSE, high = FALSE),
                                      error.rep = TRUE, error.fold = TRUE)
```

### parsperrorest.old mit par.mode = 1 (`parallel::mclapply()`)

* Läuft nur auf Unix Systemen!!

```{r}
mclapply.out <- parsperrorest.old(data = ecuador, formula = fo,
                                  model.fun = rpart, model.args = list(control = ctrl),
                                  pred.fun = mypred.rpart,
                                  smp.fun = partition.cv, 
                                  smp.args = list(repetition = 1:20, nfold = 5), 
                                  par.args = list(par.mode = 3, par.units = 2, 
                                                  lb = FALSE, high = FALSE),
                                  error.rep = TRUE, error.fold = TRUE)
```

## parsperrorest (`pbapply::pbLapply()`)

* Basierend auf `pbapply` package
     * wrapper function für `mclapply` und `parApply` 
     * Vorteile
         * bietet progress bar auf allen Plattformen
         * Reduziert par.args wie `lb` und `high` weil es nur die jeweils effizientesten nutzt (`lb = FALSE` und `high = TRUE`)
         * Idee ist par.mode = 1 (mclapply) automatisch auf unix systemem zu nutzen 
     und par.mode = 2 auf Windows
    

Nutzt die `pblapply` Funktion des `pbapply` packages. 
Wrapper Funktion für `parallel::mclapply` (unix) und `parallel::parApply` (Windows)

### parsperro.unix (`pbapply::pbLapply()` mit `parallel::mclapply()`)
```{r}
parsperro.unix <- parsperrorest(data = ecuador, formula = fo,
                                model.fun = rpart, model.args = list(control = ctrl),
                                pred.fun = mypred.rpart,
                                smp.fun = partition.cv, 
                                smp.args = list(repetition = 1:30, nfold = 5), 
                                par.args = list(par.mode = 1, par.units = 2),
                                error.rep = TRUE, error.fold = TRUE)
```


### parsperro.windows (`pbapply::pbLapply()` mit `parallel::parApply()`) 
```{r}
parsperro.windows <- parsperrorest(data = ecuador, formula = fo,
                                   model.fun = rpart, model.args = list(control = ctrl),
                                   pred.fun = mypred.rpart,
                                   smp.fun = partition.cv, 
                                   smp.args = list(repetition = 1:30, nfold = 5), 
                                   par.args = list(par.mode = 2, par.units = 2),
                                   error.rep = TRUE, error.fold = TRUE)
```


```{r, eval=FALSE, echo=FALSE}
setwd("~/Servers/GIServer/Master.thesis/")
d <- readRDS("~/Servers/GIServer/Master.thesis/output/SurveyData/Survey.data.clean.Rd")
# d <- read.csv("output/SurveyData/survey_points.csv")

# load packages
pacman::p_load(sp, MASS, nlme, sperrorest, tibble, mgcv, doParallel, foreach)
source("~/Servers/GIServer/Master.thesis/R/fun.R")

# convert SpPoDaFra to DaFra to create 'corSpatial' object
d <- as.data.frame(d)
# Now 'wiggle' the x/y coordinates by a negligible amount
# so that they are unique; otherwise some of the spatial
# regression models will fail because the observations at
# identical locations must be identical. And here actual 
# different obs. have the same coordinates
set.seed(1234)
d$rx <- d$lon + rnorm(nrow(d))
d$ry <- d$lat + rnorm(nrow(d))

d <- d[, c("precip", "temp", "srad", "age", "year", 
           "evaluation", "hail", "ry", "rx")]

###########
# GLMM
###########

print("GLMM")

# predictors
fo <- hail ~ precip + temp + srad + age
```

```{r, eval=FALSE, echo=FALSE}
CV = parsperrorest.old(fo, model.fun = mymodel_glmmPQL,
              data = d, coords = c("rx","ry"), pred.fun = predict,
              pred.args = list(type = "response", level = 0),
              smp.fun = partition.kmeans, 
              verbose = "all",
              smp.args = list(repetition = 1:2, nfold = 2),
              par.args = list(par.mode = 3, par.units = 2, lb = FALSE, high = T),
              error.rep = T, error.fold = F )
```
