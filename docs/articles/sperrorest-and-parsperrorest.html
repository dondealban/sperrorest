<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>sperrorest vignette: Spatial modeling using statistical learning techniques • sperrorest</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sperrorest</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>sperrorest vignette: Spatial modeling using statistical learning techniques</h1>
                        <h4 class="author">Alexander Brenning, Patrick Schratz</h4>
            
            <h4 class="date">2017-02-19</h4>
          </div>

    
    
<div class="contents">
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<html><body><a href="#introduction" class="anchor"> </a></body></html>Introduction</h1>
<p>Geospatial data scientists often make use of a variety of statistical and machine learning techniques for spatial prediction in applications such as landslide susceptibility modeling <span class="citation">(Goetz et al. <a href="#ref-Goetz2015">2015</a>)</span> or habitat modeling <span class="citation">(Knudby, Brenning, and LeDrew <a href="#ref-Knudby2010">2010</a>)</span>. Novel and often more flexible techniques promise improved predictive performances as they are better able to represent nonlinear relationships or higher-order interactions between predictors than less flexible linear models.</p>
<p>Nevertheless, this increased flexibility comes with the risk of possible over-fitting to the training data. Since nearby spatial observations often tend to be more similar than distant ones, traditional random cross-validation is unable to detect this over-fitting whenever spatial observations are close to each other (e.g. <span class="citation">Brenning (<a href="#ref-Brenning2005">2005</a>)</span>). Spatial cross-validation addresses this by resampling the data not completely randomly, but using larger spatial regions. In some cases, spatial data is grouped, e.g. in remotely-sensed land use mapping grid cells belonging to the same field share the same management procedures and cultivation history, making them more similar to each other than to pixels from other fields with the same crop type.</p>
<p>This package provides a customizable toolkit for cross-validation (and bootstrap) estimation using a variety of spatial resampling schemes. More so, this toolkit can even be extended to spatio-temporal data or other complex data structures. This vignette will walk you through a simple case study, crop classification in central Chile <span class="citation">(Peña and Brenning <a href="#ref-Pena2015">2015</a>)</span>.</p>
<p>This vignette is based on code that Alex Brenning developed for his course on ‘Environmental Statistics and GeoComputation’ that he teaches in the <a href="http://www.geographie.uni-jena.de/Studium/Studierende/Studieng%C3%A4nge/Master+of+Science+Geoinformatik+.html">Geographic Information Science Master’s program</a> at Friedrich Schiller University Jena, Germany. Please take a look at our program and spread the word!</p>
</div>
<div id="data-and-packages" class="section level1">
<h1 class="hasAnchor">
<html><body><a href="#data-and-packages" class="anchor"> </a></body></html>Data And Packages</h1>
<p>As a case study we will carry out a supervised classification analysis using remotely-sensed data to predict fruit-tree crop types in central Chile. This data set is a subsample of data from <span class="citation">(Peña and Brenning <a href="#ref-Pena2015">2015</a>)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sperrorest)
<span class="kw">library</span>(pacman)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">"maipo"</span>, <span class="dt">package =</span> <span class="st">"sperrorest"</span>)</code></pre></div>
<p>The remote-sensing predictor variables were derived from an image times series consisting of eight Landsat images acquired throughout the (southern hemisphere) growing season. The data set includes the following variables:</p>
<p><strong>Response</strong><br>
- <code>croptype</code>: response variable (factor) with 4 levels: ground truth information</p>
<p><strong>Predictors</strong><br>
- <code>b</code>[12-87]: spectral data, e.g. b82 = image date #8, spectral band #2<br>
- <code>ndvi</code>[01-08]: Normalized Difference Vegetation Index, e.g. #8 = image date #8<br>
- <code>ndwi</code>[01-08]: Normalized Difference Water Index, e.g. #8 = image date #8</p>
<p><strong>Others</strong><br>
- <code>field</code>: field identifier (grouping variable - not to be used as predictor)<br>
- <code>utmx</code>, <code>utmy</code>: x/y location; not to be used as predictors</p>
<p>All but the first four variables of the data set are predictors; their names are used to construct a formula object:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictors &lt;-<span class="st"> </span><span class="kw">colnames</span>(maipo)[<span class="dv">5</span><span class="op">:</span><span class="kw">ncol</span>(maipo)]
<span class="co"># Construct a formula:</span>
fo &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">"croptype ~"</span>, <span class="kw">paste</span>(predictors, <span class="dt">collapse =</span> <span class="st">"+"</span>)))</code></pre></div>
</div>
<div id="modeling" class="section level1">
<h1 class="hasAnchor">
<html><body><a href="#modeling" class="anchor"> </a></body></html>Modeling</h1>
<p>Here we will take a look at a few classification methods with varying degrees of computational complexity and flexibility. This should give you an idea of how different models are handled by <code>sperrorest</code>, depending on the characteristics of their fitting and prediction methods. Please refer to <span class="citation">(James et al. <a href="#ref-James2013">2013</a>)</span> for background information on the models used here.</p>
<div id="linear-discriminant-analysis-lda" class="section level2">
<h2 class="hasAnchor">
<html><body><a href="#linear-discriminant-analysis-lda" class="anchor"> </a></body></html>Linear Discriminant Analysis (LDA)</h2>
<p>LDA is simple and fast, and often performs surprisingly well if the problem at hand is ‘linear enough’. As a start, let’s fit a model with all predictors and using all available data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">p_load</span>(MASS)
fit &lt;-<span class="st"> </span><span class="kw">lda</span>(fo, <span class="dt">data =</span> maipo)</code></pre></div>
<p>Predict the croptype with the fitted model and calculate the misclassification error rate (MER) on the training sample:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> maipo)<span class="op">$</span>class
<span class="kw">mean</span>(pred <span class="op">!=</span><span class="st"> </span>maipo<span class="op">$</span>croptype)
## [1] 0.04369247</code></pre></div>
<p>But remember that this result is over-optimistic because we are re-using the training sample for model evaluation. We will soon show you how to do better with cross-validation.</p>
<p>We can also take a look at the confusion matrix but again, this result is overly optimistic:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(<span class="dt">pred =</span> pred, <span class="dt">obs =</span> maipo<span class="op">$</span>croptype)
##        obs
## pred    crop1 crop2 crop3 crop4
##   crop1  1294     8     4    37
##   crop2    50  1054     4    44
##   crop3     0     0  1935     6
##   crop4    45   110    29  3093</code></pre></div>
</div>
<div id="classification-tree" class="section level2">
<h2 class="hasAnchor">
<html><body><a href="#classification-tree" class="anchor"> </a></body></html>Classification Tree</h2>
<p>Classification and regresion trees (CART) take a completely different approach—they are based on yes/no questions in the predictor variables and can be referred to as a binary partitioning technique. Fit a model with all predictors and default settings:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">rpart</span>(fo, <span class="dt">data =</span> maipo)

## optional: view the classiciation tree
<span class="co"># par(xpd = TRUE)</span>
<span class="co"># plot(fit)</span>
<span class="co"># text(fit, use.n = TRUE)</span></code></pre></div>
<p>Again, predict the croptype with the fitted model and calculate the average MER:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> maipo, <span class="dt">type =</span> <span class="st">"class"</span>)
<span class="kw">mean</span>(pred <span class="op">!=</span><span class="st"> </span>maipo<span class="op">$</span>croptype)
## [1] 0.1127966</code></pre></div>
<p>Here the <code>predict</code> call is slightly different. Again, we could calculate a confusion matrix.</p>
</div>
<div id="bagging-ipred" class="section level2">
<h2 class="hasAnchor">
<html><body><a href="#bagging-ipred" class="anchor"> </a></body></html>Bagging (ipred)</h2>
<p>Bagging, bundling and random forests build upon the CART technique by fitting many trees on bootstrap resamples of the original data set <span class="citation">(Breiman <a href="#ref-Breiman1996">1996</a>)</span> <span class="citation">(Breiman <a href="#ref-Breiman2001">2001</a>)</span> <span class="citation">(Hothorn and Lausen <a href="#ref-Hothorn2005">2005</a>)</span>. They differ in that random forest also samples from the predictors, and bundling adds an ancillary classifier for improved classification. We will use the simpler bagging technique <span class="citation">(Breiman <a href="#ref-Breiman1996">1996</a>)</span>. (For some reason the <code>randomForest()</code> implementation causes problems when using the parallelized code later; it does work with the sequential version of <code><a href="../reference/sperrorest.html">sperrorest()</a></code> though.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ipred)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">bagging</span>(fo, <span class="dt">data =</span> maipo, <span class="dt">coob =</span> <span class="ot">TRUE</span>)
fit
## 
## Bagging classification trees with 25 bootstrap replications 
## 
## Call: bagging.data.frame(formula = fo, data = maipo, coob = TRUE)
## 
## Out-of-bag estimate of misclassification error:  0.0182</code></pre></div>
<p>Let’s take a look at the MER achieved on the training sample:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> maipo, <span class="dt">type =</span> <span class="st">"class"</span>)
<span class="kw">mean</span>(pred <span class="op">!=</span><span class="st"> </span>maipo<span class="op">$</span>croptype)
## [1] 0</code></pre></div>
<p>Isn’t this amazing? Only one grid cell is misclassified by the bagging classifier! Even the OOB (out-of-bag) estimate of the error rate is &lt; 1%. Too good to be true? We’ll see…</p>
</div>
</div>
<div id="cross-validation-estimation-of-predictive-performance" class="section level1">
<h1 class="hasAnchor">
<html><body><a href="#cross-validation-estimation-of-predictive-performance" class="anchor"> </a></body></html>Cross-Validation Estimation of Predictive Performance</h1>
<p>Of course we can’t take the MER on the training set too seriously—it is biased. But we’ve heard of cross-validation, in which disjoint subsets are used for model training and testing. Let’s use <code>sperrorest</code> for cross-validation.</p>
<p>Also, at this point we should highlight that the observations in this data set are pixels, and multiple grid cells belong to the same field. In a predictive situation, and when field boundaries are known (as is the case here), we would want to predict the same class for all grid cells that belong to the same field. Here we will use a majority filter.</p>
<div id="linear-discriminant-analysis-lda-1" class="section level2">
<h2 class="hasAnchor">
<html><body><a href="#linear-discriminant-analysis-lda-1" class="anchor"> </a></body></html>Linear Discriminant Analysis (LDA)</h2>
<p>First, we need to create a wrapper predict method for LDA for <code><a href="../reference/sperrorest.html">sperrorest()</a></code>. This is necessary in order to accomodate the majority filter, and also because class predictions from <code>lda</code>’s predict method are hidden in the <code>$class</code> component of the returned object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lda.predfun &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata, <span class="dt">fac =</span> <span class="ot">NULL</span>) {
  
  <span class="kw">p_load</span>(nnet)
  majority &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
    <span class="kw">levels</span>(x)[<span class="kw">which.is.max</span>(<span class="kw">table</span>(x))]
  }
  
  majority.filter &lt;-<span class="st"> </span><span class="cf">function</span>(x, fac) {
    <span class="cf">for</span> (lev <span class="cf">in</span> <span class="kw">levels</span>(fac)) {
      x[fac <span class="op">==</span><span class="st"> </span>lev] &lt;-<span class="st"> </span><span class="kw">majority</span>(x[fac <span class="op">==</span><span class="st"> </span>lev])
    }
    x
  }
  
  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(object, <span class="dt">newdata =</span> newdata)<span class="op">$</span>class
  <span class="cf">if</span> (<span class="op">!</span><span class="kw">is.null</span>(fac)) pred &lt;-<span class="st"> </span><span class="kw">majority.filter</span>(pred, newdata[, fac]) 
  <span class="kw">return</span>(pred)
}</code></pre></div>
<p>To ensure that custom predict-functions do also work with <code><a href="../reference/parsperrorest.html">parsperrorest()</a></code>, we need to define all custom functions in one step. Otherwise, the <code>foreach()</code> package in <code>par.mode = 2</code> of <code><a href="../reference/parsperrorest.html">parsperrorest()</a></code> will throw errors because of the way how it loads functions of the parent environment.</p>
<p>Finally, we can run <code><a href="../reference/sperrorest.html">sperrorest()</a></code> with a non-spatial sampling setup (<code><a href="../reference/partition.cv.html">partition.cv()</a></code>). Since we’re impatient, we’ll use five folds (partitions) and only six repetitions; more repetitions are recommended to obtain results that are independent of the particular random partitioning.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res.lda.nsp &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sperrorest.html">sperrorest</a></span>(fo, <span class="dt">data =</span> maipo, <span class="dt">coords =</span> <span class="kw">c</span>(<span class="st">"utmx"</span>,<span class="st">"utmy"</span>), 
                          <span class="dt">model.fun =</span> lda,
                          <span class="dt">pred.fun =</span> lda.predfun, 
                          <span class="dt">pred.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>),
                          <span class="dt">smp.fun =</span> partition.cv, 
                          <span class="dt">smp.args =</span> <span class="kw">list</span>(<span class="dt">repetition =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nfold =</span> <span class="dv">5</span>),
                          <span class="dt">error.rep =</span> <span class="ot">TRUE</span>, <span class="dt">error.fold =</span> <span class="ot">FALSE</span>)
## Sun Feb 19 21:19:07 2017 Repetition 1 
## Sun Feb 19 21:19:07 2017 - Fold 1 
## Sun Feb 19 21:19:10 2017 - Fold 2 
## Sun Feb 19 21:19:12 2017 - Fold 3 
## Sun Feb 19 21:19:14 2017 - Fold 4 
## Sun Feb 19 21:19:16 2017 - Fold 5 
## Sun Feb 19 21:19:18 2017 Repetition 2 
## Sun Feb 19 21:19:18 2017 - Fold 1 
## Sun Feb 19 21:19:20 2017 - Fold 2 
## Sun Feb 19 21:19:22 2017 - Fold 3 
## Sun Feb 19 21:19:24 2017 - Fold 4 
## Sun Feb 19 21:19:27 2017 - Fold 5 
## Sun Feb 19 21:19:29 2017 Repetition 3 
## Sun Feb 19 21:19:29 2017 - Fold 1 
## Sun Feb 19 21:19:31 2017 - Fold 2 
## Sun Feb 19 21:19:32 2017 - Fold 3 
## Sun Feb 19 21:19:34 2017 - Fold 4 
## Sun Feb 19 21:19:36 2017 - Fold 5 
## Sun Feb 19 21:19:38 2017 Repetition 4 
## Sun Feb 19 21:19:38 2017 - Fold 1 
## Sun Feb 19 21:19:40 2017 - Fold 2 
## Sun Feb 19 21:19:42 2017 - Fold 3 
## Sun Feb 19 21:19:44 2017 - Fold 4 
## Sun Feb 19 21:19:46 2017 - Fold 5 
## Sun Feb 19 21:19:48 2017 Repetition 5 
## Sun Feb 19 21:19:48 2017 - Fold 1 
## Sun Feb 19 21:19:50 2017 - Fold 2 
## Sun Feb 19 21:19:52 2017 - Fold 3 
## Sun Feb 19 21:19:55 2017 - Fold 4 
## Sun Feb 19 21:19:56 2017 - Fold 5 
## Sun Feb 19 21:19:59 2017 Repetition 6 
## Sun Feb 19 21:19:59 2017 - Fold 1 
## Sun Feb 19 21:20:01 2017 - Fold 2 
## Sun Feb 19 21:20:02 2017 - Fold 3 
## Sun Feb 19 21:20:04 2017 - Fold 4 
## Sun Feb 19 21:20:07 2017 - Fold 5 
## Sun Feb 19 21:20:09 2017 Done.
<span class="kw">round</span>(<span class="kw">summary</span>(res.lda.nsp<span class="op">$</span>error.rep), <span class="dv">3</span>)
##                     mean    sd    median   IQR
## train.error        0.034 0.000     0.034 0.000
## train.accuracy     0.966 0.000     0.966 0.000
## train.events    4688.000 0.000  4688.000 0.000
## train.count    30852.000 0.000 30852.000 0.000
## test.error         0.041 0.001     0.041 0.001
## test.accuracy      0.959 0.001     0.959 0.001
## test.events     1172.000 0.000  1172.000 0.000
## test.count      7713.000 0.000  7713.000 0.000</code></pre></div>
<p>To run a spatial cross-validation at the field level, we can use <code><a href="../reference/partition.factor.cv.html">partition.factor.cv()</a></code> as the sampling function. Subsequently, we have to specify the location of the fields. We can do so using the <code>field</code> variable of our data set and put in <code>smp.args</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res.lda.sp &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sperrorest.html">sperrorest</a></span>(fo, <span class="dt">data =</span> maipo, <span class="dt">coords =</span> <span class="kw">c</span>(<span class="st">"utmx"</span>,<span class="st">"utmy"</span>), 
                         <span class="dt">model.fun =</span> lda,
                         <span class="dt">pred.fun =</span> lda.predfun, 
                         <span class="dt">pred.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>),
                         <span class="dt">smp.fun =</span> partition.factor.cv,
                         <span class="dt">smp.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>, <span class="dt">repetition =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nfold =</span> <span class="dv">5</span>),
                         <span class="dt">error.rep =</span> <span class="ot">TRUE</span>, <span class="dt">error.fold =</span> <span class="ot">FALSE</span>, 
                         <span class="dt">benchmark =</span> <span class="ot">TRUE</span>)
## Sun Feb 19 21:20:09 2017 Repetition 1 
## Sun Feb 19 21:20:09 2017 - Fold 1 
## Sun Feb 19 21:20:12 2017 - Fold 2 
## Sun Feb 19 21:20:14 2017 - Fold 3 
## Sun Feb 19 21:20:16 2017 - Fold 4 
## Sun Feb 19 21:20:18 2017 - Fold 5 
## Sun Feb 19 21:20:20 2017 Repetition 2 
## Sun Feb 19 21:20:20 2017 - Fold 1 
## Sun Feb 19 21:20:22 2017 - Fold 2 
## Sun Feb 19 21:20:24 2017 - Fold 3 
## Sun Feb 19 21:20:26 2017 - Fold 4 
## Sun Feb 19 21:20:28 2017 - Fold 5 
## Sun Feb 19 21:20:30 2017 Repetition 3 
## Sun Feb 19 21:20:30 2017 - Fold 1 
## Sun Feb 19 21:20:32 2017 - Fold 2 
## Sun Feb 19 21:20:34 2017 - Fold 3 
## Sun Feb 19 21:20:36 2017 - Fold 4 
## Sun Feb 19 21:20:38 2017 - Fold 5 
## Sun Feb 19 21:20:40 2017 Repetition 4 
## Sun Feb 19 21:20:40 2017 - Fold 1 
## Sun Feb 19 21:20:42 2017 - Fold 2 
## Sun Feb 19 21:20:43 2017 - Fold 3 
## Sun Feb 19 21:20:45 2017 - Fold 4 
## Sun Feb 19 21:20:47 2017 - Fold 5 
## Sun Feb 19 21:20:49 2017 Repetition 5 
## Sun Feb 19 21:20:49 2017 - Fold 1 
## Sun Feb 19 21:20:51 2017 - Fold 2 
## Sun Feb 19 21:20:53 2017 - Fold 3 
## Sun Feb 19 21:20:55 2017 - Fold 4 
## Sun Feb 19 21:20:57 2017 - Fold 5 
## Sun Feb 19 21:20:59 2017 Repetition 6 
## Sun Feb 19 21:20:59 2017 - Fold 1 
## Sun Feb 19 21:21:01 2017 - Fold 2 
## Sun Feb 19 21:21:03 2017 - Fold 3 
## Sun Feb 19 21:21:05 2017 - Fold 4 
## Sun Feb 19 21:21:07 2017 - Fold 5 
## Sun Feb 19 21:21:09 2017 Done.
res.lda.sp<span class="op">$</span>benchmark<span class="op">$</span>runtime.performance
## Time difference of 59.18108 secs</code></pre></div>
<!-- In order to speed up the calculation on a multicore CPU, we can use `parsperrorest()`. Here an example using two cores: -->
<!-- ```{r} -->
<!-- #### läuft nicht, da 'out.of.bounds' error wenn partition.factor.cv + custom pred.fun -->
<!-- res.lda.sp.par <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), -->
<!--                                 model.fun = lda, -->
<!--                                 pred.fun = lda.predfun, -->
<!--                                 pred.args = list(fac = "field"), -->
<!--                                 smp.fun = partition.factor.cv, -->
<!--                                 smp.args = list(fac = "field", repetition = 1:6, nfold = 5), -->
<!--                                 par.args = list(par.units = 2, par.mode = 2), -->
<!--                                 error.rep = TRUE, error.fold = TRUE, -->
<!--                                 benchmark = TRUE) -->
<!-- res.lda.sp.par$benchmark$runtime.performance -->
<!-- ``` -->
<!-- ```{r} -->
<!-- res.lda.par <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"),  -->
<!--                                model.fun = lda, -->
<!--                                pred.fun = lda.predfun,  -->
<!--                                pred.args = list(fac = "field"), -->
<!--                                smp.fun = partition.cv, -->
<!--                                smp.args = list(repetition = 1:6, nfold = 5), -->
<!--                                par.args = list(par.units = 2, par.mode = 2), -->
<!--                                error.rep = TRUE, error.fold = TRUE, -->
<!--                                benchmark = TRUE) -->
<!-- res.lda.par$benchmark$runtime.performance -->
<!-- ``` -->
</div>
<div id="bagging" class="section level2">
<h2 class="hasAnchor">
<html><body><a href="#bagging" class="anchor"> </a></body></html>Bagging</h2>
<p>In the case of bagging, the customized <code>pred.fun</code> looks as follows; it is only required because of the majority filter, without it, we could just omit the <code>pred.fun</code> and <code>pred.args</code> arguments below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bagg.predfun &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata, <span class="dt">fac =</span> <span class="ot">NULL</span>) {
    
    <span class="kw">p_load</span>(nnet)
    majority &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
      <span class="kw">levels</span>(x)[<span class="kw">which.is.max</span>(<span class="kw">table</span>(x))]
    }
    
    majority.filter &lt;-<span class="st"> </span><span class="cf">function</span>(x, fac) {
      <span class="cf">for</span> (lev <span class="cf">in</span> <span class="kw">levels</span>(fac)) {
        x[fac <span class="op">==</span><span class="st"> </span>lev] &lt;-<span class="st"> </span><span class="kw">majority</span>(x[fac <span class="op">==</span><span class="st"> </span>lev])
      }
      x
    }
    
    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(object, <span class="dt">newdata =</span> newdata)
    <span class="cf">if</span> (<span class="op">!</span><span class="kw">is.null</span>(fac)) pred &lt;-<span class="st"> </span><span class="kw">majority.filter</span>(pred, newdata[,fac]) 
    <span class="kw">return</span>(pred)
  }</code></pre></div>
<p>Running <code><a href="../reference/sperrorest.html">sperrorest()</a></code> takes some time here (a few minutes depending on your CPU power).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res.bagg.sp &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sperrorest.html">sperrorest</a></span>(fo, <span class="dt">data =</span> maipo, <span class="dt">coords =</span> <span class="kw">c</span>(<span class="st">"utmx"</span>,<span class="st">"utmy"</span>), 
                          <span class="dt">model.fun =</span> bagging,
                          <span class="dt">pred.fun =</span> bagg.predfun,
                          <span class="dt">pred.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>),
                          <span class="dt">smp.fun =</span> partition.factor.cv,
                          <span class="dt">smp.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>,
                                          <span class="dt">repetition =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nfold =</span> <span class="dv">5</span>),
                          <span class="dt">error.rep =</span> <span class="ot">TRUE</span>, <span class="dt">error.fold =</span> <span class="ot">TRUE</span>,
                          <span class="dt">benchmark =</span> <span class="ot">TRUE</span>, <span class="dt">progress =</span> <span class="dv">1</span>)
## Sun Feb 19 21:21:50 2017 Repetition 1 
## Sun Feb 19 21:21:50 2017 - Fold 1 
## Sun Feb 19 21:22:00 2017 - Fold 2 
## Sun Feb 19 21:22:10 2017 - Fold 3 
## Sun Feb 19 21:22:20 2017 - Fold 4 
## Sun Feb 19 21:22:30 2017 - Fold 5 
## Sun Feb 19 21:22:40 2017 Repetition 2 
## Sun Feb 19 21:22:40 2017 - Fold 1 
## Sun Feb 19 21:22:49 2017 - Fold 2 
## Sun Feb 19 21:22:59 2017 - Fold 3 
## Sun Feb 19 21:23:08 2017 - Fold 4 
## Sun Feb 19 21:23:17 2017 - Fold 5 
## Sun Feb 19 21:23:27 2017 Repetition 3 
## Sun Feb 19 21:23:27 2017 - Fold 1 
## Sun Feb 19 21:23:36 2017 - Fold 2 
## Sun Feb 19 21:23:45 2017 - Fold 3 
## Sun Feb 19 21:23:54 2017 - Fold 4 
## Sun Feb 19 21:24:04 2017 - Fold 5 
## Sun Feb 19 21:24:13 2017 Repetition 4 
## Sun Feb 19 21:24:13 2017 - Fold 1 
## Sun Feb 19 21:24:22 2017 - Fold 2 
## Sun Feb 19 21:24:31 2017 - Fold 3 
## Sun Feb 19 21:24:41 2017 - Fold 4 
## Sun Feb 19 21:24:50 2017 - Fold 5 
## Sun Feb 19 21:24:59 2017 Repetition 5 
## Sun Feb 19 21:24:59 2017 - Fold 1 
## Sun Feb 19 21:25:08 2017 - Fold 2 
## Sun Feb 19 21:25:17 2017 - Fold 3 
## Sun Feb 19 21:25:27 2017 - Fold 4 
## Sun Feb 19 21:25:35 2017 - Fold 5 
## Sun Feb 19 21:25:44 2017 Repetition 6 
## Sun Feb 19 21:25:44 2017 - Fold 1 
## Sun Feb 19 21:25:54 2017 - Fold 2 
## Sun Feb 19 21:26:03 2017 - Fold 3 
## Sun Feb 19 21:26:12 2017 - Fold 4 
## Sun Feb 19 21:26:21 2017 - Fold 5 
## Sun Feb 19 21:26:30 2017 Done.
res.bagg.sp<span class="op">$</span>benchmark<span class="op">$</span>runtime.performance
## Time difference of 4.671897 mins</code></pre></div>
<p>What a surprise! Bagging classification isn’t that good after all, if we acknowledge that in ‘real life’ we wouldn’t be making predictions in situations where the class membership of other grid cells in the same field is known in the training stage. So spatial dependence does matter.</p>
</div>
<div id="parallelized-cross-validation" class="section level2">
<h2 class="hasAnchor">
<html><body><a href="#parallelized-cross-validation" class="anchor"> </a></body></html>Parallelized cross-validation</h2>
<p>To speed things up, we can use <code><a href="../reference/parsperrorest.html">parsperrorest()</a></code> and inspect the runtime difference. Note that we have two parallel modes to choose from!<br>
In this example we will use <code>par.mode = 2</code> because <code>par.mode = 1</code> will not work in this example (reason unknown—we’re working on it). In this vignette we will always use 2 cores to ensure that this example is working for everybody.<br>
You can of course increase the number of cores depending on your hardware. Note that we will not use any console outputs in this vignette to keep it tidy. However you can change this setting using the <code>progress</code> argument.</p>
<p><strong>Details of argument <code>par.mode</code></strong></p>
<p>The advantage of <code>par.mode = 1</code> compared to <code>par.mode = 2</code> is its speed. However, <code>par.mode = 1</code> is less stable. This means that <code>par.mode = 1</code> will throws errors for models which <code>par.mode = 2</code> will execute properly. <code>par.mode = 1</code> uses either a <code>parallel::mclapply()</code> (Unix) or <code>parallel::parApply()</code> (Windows) while <code>par.mode = 2</code> is running on a <code>foreach</code> backend.</p>
<p>While traditional <code>mclapply()</code> approaches have the downside that no progress report can be printed, the <code>pbapply</code> package implemented in <code><a href="../reference/parsperrorest.html">parsperrorest()</a></code> provides console output and does even work cross-platform.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res.bagg.sp.par &lt;-<span class="st"> </span><span class="kw"><a href="../reference/parsperrorest.html">parsperrorest</a></span>(fo, <span class="dt">data =</span> maipo, <span class="dt">coords =</span> <span class="kw">c</span>(<span class="st">"utmx"</span>,<span class="st">"utmy"</span>), 
                                 <span class="dt">model.fun =</span> bagging,
                                 <span class="dt">pred.fun =</span> bagg.predfun,
                                 <span class="dt">pred.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>),
                                 <span class="dt">smp.fun =</span> partition.factor.cv,
                                 <span class="dt">smp.args =</span> <span class="kw">list</span>(<span class="dt">fac =</span> <span class="st">"field"</span>, 
                                                 <span class="dt">repetition =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nfold =</span> <span class="dv">5</span>),
                                 <span class="dt">par.args =</span> <span class="kw">list</span>(<span class="dt">par.units =</span> <span class="dv">2</span>, <span class="dt">par.mode =</span> <span class="dv">2</span>),
                                 <span class="dt">error.rep =</span> <span class="ot">TRUE</span>, <span class="dt">error.fold =</span> <span class="ot">TRUE</span>,
                                 <span class="dt">benchmark =</span> <span class="ot">TRUE</span>)
## Sun Feb 19 21:29:23 2017 Done.
res.bagg.sp.par<span class="op">$</span>benchmarks<span class="op">$</span>runtime.performance
## Time difference of 2.884783 mins</code></pre></div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<html><body><a href="#references" class="anchor"> </a></body></html>References</h1>
<div id="refs" class="references">
<div id="ref-Breiman1996">
<p>Breiman, Leo. 1996. “Bagging Predictors.” <em>Machine Learning</em> 24 (2). Springer Nature: 123–40. doi:<a href="https://doi.org/10.1007/bf00058655">10.1007/bf00058655</a>.</p>
</div>
<div id="ref-Breiman2001">
<p>———. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1). Springer Nature: 5–32. doi:<a href="https://doi.org/10.1023/a:1010933404324">10.1023/a:1010933404324</a>.</p>
</div>
<div id="ref-Brenning2005">
<p>Brenning, A. 2005. “Spatial Prediction Models for Landslide Hazards: Review, Comparison and Evaluation.” <em>Natural Hazards and Earth System Science</em> 5 (6). Copernicus GmbH: 853–62. doi:<a href="https://doi.org/10.5194/nhess-5-853-2005">10.5194/nhess-5-853-2005</a>.</p>
</div>
<div id="ref-Goetz2015">
<p>Goetz, J.N., A. Brenning, H. Petschko, and P. Leopold. 2015. “Evaluating Machine Learning and Statistical Prediction Techniques for Landslide Susceptibility Modeling.” <em>Computers &amp; Geosciences</em> 81 (August). Elsevier BV: 1–11. doi:<a href="https://doi.org/10.1016/j.cageo.2015.04.007">10.1016/j.cageo.2015.04.007</a>.</p>
</div>
<div id="ref-Hothorn2005">
<p>Hothorn, Torsten, and Berthold Lausen. 2005. “Bundling Classifiers by Bagging Trees.” <em>Computational Statistics &amp; Data Analysis</em> 49 (4). Elsevier BV: 1068–78. doi:<a href="https://doi.org/10.1016/j.csda.2004.06.019">10.1016/j.csda.2004.06.019</a>.</p>
</div>
<div id="ref-James2013">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Springer New York. doi:<a href="https://doi.org/10.1007/978-1-4614-7138-7">10.1007/978-1-4614-7138-7</a>.</p>
</div>
<div id="ref-Knudby2010">
<p>Knudby, Anders, Alexander Brenning, and Ellsworth LeDrew. 2010. “New Approaches to Modelling Fishhabitat Relationships.” <em>Ecological Modelling</em> 221 (3). Elsevier BV: 503–11. doi:<a href="https://doi.org/10.1016/j.ecolmodel.2009.11.008">10.1016/j.ecolmodel.2009.11.008</a>.</p>
</div>
<div id="ref-Pena2015">
<p>Peña, M.A., and A. Brenning. 2015. “Assessing Fruit-Tree Crop Classification from Landsat-8 Time Series for the Maipo Valley, Chile.” <em>Remote Sensing of Environment</em> 171 (December). Elsevier BV: 234–44. doi:<a href="https://doi.org/10.1016/j.rse.2015.10.029">10.1016/j.rse.2015.10.029</a>.</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#data-and-packages">Data And Packages</a></li>
      <li>
<a href="#modeling">Modeling</a><ul class="nav nav-pills nav-stacked">
<li><a href="#linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</a></li>
      <li><a href="#classification-tree">Classification Tree</a></li>
      <li><a href="#bagging-ipred">Bagging (ipred)</a></li>
      </ul>
</li>
      <li>
<a href="#cross-validation-estimation-of-predictive-performance">Cross-Validation Estimation of Predictive Performance</a><ul class="nav nav-pills nav-stacked">
<li><a href="#linear-discriminant-analysis-lda-1">Linear Discriminant Analysis (LDA)</a></li>
      <li><a href="#bagging">Bagging</a></li>
      <li><a href="#parallelized-cross-validation">Parallelized cross-validation</a></li>
      </ul>
</li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Alexander Brenning, Patrick Schratz, Tobias Herrmann.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
